# in order to allow for multiple annotation process to coexist and produce similar names output, we just define rules priority
# if parse_cogs_annotation does not work, it tries annotation_diamond
ruleorder:  koannotation > parse_hmmsearch_annotation  > annotation_diamond
 
# ---- prodigal annotation on splits ----------------------------------------------------------------
rule prodigal:
    input:
        "{group}/contigs/contigs.fa"
    output:
        faa="{group}/annotation/contigs.faa",
        fna="{group}/annotation/contigs.fna",
        gff="{group}/annotation/contigs.gff",
        cut_faa=expand("{{group}}/annotation/temp_splits/Batch_{nb}.faa",nb=range(100))
    params:
        dir='{group}/annotation'
    threads: 32
    resources:
        slurm_partition = get_resource("partition",mult=10),
        mem_mb = get_resource("mem",mult=10)
    message:"Parallel prodigal run in {input}"
    conda : CONDA_ENV + "/prodigal.yaml"
    singularity : "docker://quay.io/annacprice/prodigal:2.6.3"
    shell:
        "{SCRIPTS}/Parallel_prodigal.py {threads} {input} -s 100 -o {params.dir} -T {params.dir}/temp_splits"

# ---- diamond annotation  ----------------------------------------------------------------
rule diamond:
    input :  faa = "{filename}.faa",
             db = lambda w: DIAMOND[w.annotation]["db"]
    output : "{filename}_{annotation}.m8"
    log:     "{filename}_{annotation}_diamond.log"
    threads:  20
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    conda : CONDA_ENV + "/diamond.yaml"
    singularity : "docker://quay.io/annacprice/diamond:2.0.6"
    shell :   "diamond blastp --more-sensitive -d {input.db}  -q {input.faa} -p {threads} -o {output} -f6 qseqid sseqid qstart qend qlen sstart send slen length pident evalue bitscore &>{log}"

rule annotation_diamond:
    input :  "{group}/annotation/{filename}_{annotation}.m8"
    output : "{group}/annotation/{filename}_{annotation}_best_hits.tsv"
    conda : CONDA_ENV + "/pythonenv.yaml"
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    singularity : "docker://quay.io/annacprice/pythonenv:3.9"
    params : annotation=lambda w: DIAMOND[w.annotation]["annotation"],
             Bitscore=lambda w: DIAMOND[w.annotation]["filter"][0],
             Evalue=lambda w: DIAMOND[w.annotation]["filter"][1],
             PID=lambda w: DIAMOND[w.annotation]["filter"][2],
             subject_pid=lambda w: DIAMOND[w.annotation]["filter"][3],
             subject_coverage=lambda w: DIAMOND[w.annotation]["filter"][4],
             querry_coverage=lambda w: DIAMOND[w.annotation]["filter"][5],
    shell :   "{SCRIPTS}/M8_Filtering.py {input} -D {params.annotation} -B {params.Bitscore} -E {params.Evalue} -P {params.PID} -R {params.subject_pid} -C {params.subject_coverage} -Q {params.querry_coverage}  >{output}"



# ---- KO annotation taken from enrichm  --------------------
rule koannotation:
    input :  expand("{{path}}/temp_splits/Batch_{nb}.faa",nb=range(100))
    output : out = "{path}/contigs_KEGG_best_hits.tsv"
    params: root = realpath("{path}")
    conda: "%s/ko_annotation.yaml"%CONDA_ENV
    threads: 1000
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    shell: """
    snakemake -s {LOCAL_DIR}/ko_annotation.snake -k --rerun-incomplete --directory {params.root} --cores {threads} --nolock --config scripts={SCRIPTS} ROOT={params.root} KO_HMM={KO_HMM} KO_HMM_CUTOFFS={KO_HMM_CUTOFFS} CONFIG_PATH={CONFIG_PATH}
    rm -rf {params.root}/.snakemake
    """

# ---- plasmid annotation  --------------------
rule plasmidnet:
    input: "{path}/Batch_{nb}.faa"
    output:  "{path}/Batch_{nb}_contig_results.tab"
    singularity: "singularity_container/plasmidnet.sif"
    conda: "%s/plasmidnet.yaml"%CONDA_ENV
    threads: 1
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    shell: "python {PLASMIDNET}/bin/plasmidnet.py -f {input} -o $(dirname {output}) -m {PLASMIDNET}/model.zip -j {threads}"

rule generate_result_file:
    input: expand("{{path}}/annotation/temp_splits/Batch_{nb}_contig_results.tab",nb=range(1,100))
    output: results = "{path}/plasmidnet/results.tsv"
    run:
        with open(output["results"],"w") as handle:
            handle.write("contig\tbacterial_genes\tplasmid_genes\tgenes_in_total\tvote\n")
            for file in input:
                handle.writelines(line for index,line in enumerate(open(file)) if index>0)


# ---- virsorter  --------------------
rule virsorter2:
    input: "{path}/contigs/contigs.fa"
    output: "{path}/virsorter2/final-viral-boundary.tsv"
    conda: "%s/virsorter2.yaml"%CONDA_ENV
    singularity: "singularity_container/virsorter2.sif"
    threads: 32
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    shell: """
           virsorter config --init-source --db-dir={VIRSORTER_DB}
           virsorter run -w $(dirname {output}) -i {input} --min-length 1500 -j {threads} all
           """

# ------ taxonomic annotation  --------------------
if CAT_DB:
    CAT_DB_DMND = glob.glob("%s/db/*.dmnd"%CAT_DB)[0] # for size purpose
else:
    CAT_DB_DMND =""
rule CAT_annotation:
    input: contigs="{group}/contigs/contigs.fa",
           faa="{group}/annotation/contigs.faa",
           db = CAT_DB_DMND
    output: ORF2LCA="{group}/annotation/CAT/contigs.contig2classification.txt"
    params : Dir="{group}/annotation/CAT/contigs"
    conda : CONDA_ENV + "/cat.yaml"
    # singularity : "docker://quay.io/annacprice/cat:5.2.2"
    threads: 32
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    shell : """
    {CAT_PATH}/CAT_pack contigs -c {input.contigs}  -d {CAT_DB}/db -t {CAT_DB}/tax -p {input.faa} -n {threads} --out_prefix {params.Dir} --top 11 --I_know_what_Im_doing --force
    """

rule CAT_ORF_annotation:
    input: ORF2LCA="{group}/annotation/CAT/contigs.contig2classification.txt"
    output: annotation="{group}/annotation/CAT_contigs_taxonomy.tsv"
    conda : CONDA_ENV + "/cat.yaml"
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    shell: "cp {input} {output}" # add name not needed anymore, will be supported in the futur
    # singularity : "docker://quay.io/annacprice/cat:5.2.2"
    # shell : """
    # {CAT_PATH}/CAT_pack add_names -i {input.ORF2LCA} -o {output.annotation} -t {CAT_DB} --only_official
    # """

# ------- kraken annotation -----------------------
rule kraken_uniq:
    input: fa = "{group}/contigs/contigs.fa",
           db = "%s"%KRAKEN_DB
    output: report = "{group}/annotation/kraken_taxonomy_report.tsv",
            classif = "{group}/annotation/kraken_contig_taxonomy.tsv"
    conda : CONDA_ENV + "/kraken.yaml"
    singularity: "docker://quay.io/annacprice/krakenuniq:0.5.8"
    threads: 20
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    shell : """
    krakenuniq --db {input.db} --preload --fasta-input {input.fa} --threads {threads} --report-file {output.report} > {output.classif}
    """


# ------------------------------------------ COG Annotation -------------------------------
# use hmmsearch to annotate pfam markers
rule hmmsearch:
    input: faa = "{path}.faa",
           db = "%s"%SCG_HMM
    output:"{path}_hmm.out"
    conda : "%s/checkm.yaml"%CONDA_ENV
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    singularity: "docker://quay.io/annacprice/gtdbtk:1.4.0"
    log: "{path}_hmm.log"
    shell: """
    if [ ! -s {input.faa} ]
    then
        touch {output}
    else
        hmmsearch --cut_tc --cpu 1 -o /dev/null --noali --domtblout {output} {input.db} {input.faa} >{log} 2>&1 
    fi
    """

#------- select best hit --------------
# TODO add a criterion on al length
rule parse_hmmsearch_annotation:
    input: Batch=expand("{{path}}/temp_splits/Batch_{nb}_hmm.out",nb=range(100))
    output: cat=temp("{path}/contigs_hmm.out"),
            cog="{path}/contigs_cogs_best_hits.tsv"
    conda : "%s/pythonenv.yaml"%CONDA_ENV
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    singularity : "docker://quay.io/annacprice/pythonenv:3.9"
    shell: """cat {input}> {output.cat}
             {SCRIPTS}/Filter_scg_hmm.py {output.cat} --cog_hmm {SCG_DATA}/scg_hmm_selected.txt {output.cog}"""


rule IP_annotation_single_batch:
    input:
        faa="{group}/annotation/temp_splits/Batch_{nb}.faa"
    output:
        tsv=temp("{group}/annotation/temp_splits/Batch_{nb}.tsv")
    conda: CONDA_ENV + "/ip.yaml"
    singularity: "docker://interpro/interproscan"
    resources: 
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem"),
        cpus_per_task=32,
        runtime=5000,
    threads: 32
    shell: """
    sed 's/*//g' {input.faa} > {input.faa}.no_asterisks
    {IP_DB}/interproscan.sh -T $TMPDIR -goterms --iprlookup -dp -dra --cpu 32 -i {input.faa}.no_asterisks -o {output.tsv} -f TSV
    rm {input.faa}.no_asterisks
    """

rule IP_annotation_combine:
    input:
        tsv=expand("{{group}}/annotation/temp_splits/Batch_{nb}.tsv", nb=range(100))
    output:
        TSV="{group}/annotation/ip_contigs.tsv"
    shell: """
    cat {input.tsv} > {output.TSV}
    """

# ------------- genomad ------------
rule genomad:
    input: contigs = "{group}/contigs/contigs.fa", 
           DB = "%s"%GENOMAD_DB
    output: "{group}/annotation/genomad/genomad.done"
    threads: 25
    resources:
        slurm_partition = get_resource("partition"),
        mem_mb = get_resource("mem")
    params: output = "{group}/annotation/genomad"
    singularity: "docker://quay.io/biocontainers/genomad:1.8.0--pyhdfd78af_0"
    shell: """genomad end-to-end --cleanup --splits {threads} {input.contigs} {params.output} {GENOMAD_DB}&& touch {output}"""
